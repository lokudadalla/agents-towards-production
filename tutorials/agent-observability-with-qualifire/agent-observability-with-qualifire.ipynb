{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://europe-west1-atp-views-tracker.cloudfunctions.net/working-analytics?notebook=tutorials--agent-observability-with-qualifire--agent-observability-with-qualifire)\n",
        "\n",
        "# Agent observability with Qualifire üî•\n",
        "\n",
        "This notebook walks you through integrating Qualifire with a LangGraph agent to achieve comprehensive observability, including logging, tracing, and insights via OpenTelemetry.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Modern AI applications increasingly rely on sophisticated, multi-step AI agents. These agents often involve multiple LLM calls, interactions with various tools, and complex decision-making processes. Gaining clear visibility into these intricate workflows is a significant challenge. On top of all of that you might also encounter hallucinations, poor tool selection quality and other AI related risks.\n",
        "\n",
        "## Why Qualifire for Agent Observability?\n",
        "\n",
        "- **End-to-End Tracing**: Track every step of your agent's execution, from initial prompt to final output\n",
        "- **Real-Time Monitoring**: Get immediate insights into your agent's performance and behavior\n",
        "- **Debug & Troubleshoot**: Quickly identify and resolve issues in your agent's decision-making process\n",
        "- **Quality Assurance**: Monitor for hallucinations and ensure high-quality tool selection\n",
        "- **OpenTelemetry Integration**: Leverage industry-standard observability practices\n",
        "\n",
        "## Key Methods\n",
        "\n",
        "1. **Tracing Setup**: Implement distributed tracing to track agent workflows\n",
        "2. **Logging Integration**: Capture detailed logs of agent operations\n",
        "3. **Performance Monitoring**: Track response times and resource usage\n",
        "4. **Quality Metrics**: Measure and monitor agent decision quality\n",
        "\n",
        "## What you will learn\n",
        "\n",
        "1. Setup tracing and observability in your LangGraph agent\n",
        "2. Debug and troubleshoot your agent\n",
        "3. Get real-time agent observability using Qualifire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./assets/freddie-observer.png\" alt=\"Freddie Observer\" width=\"200px\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Sign up for Qualifire and Get API Key\n",
        "\n",
        "Before proceeding, make sure you have a Qualifire account and both OpenAI and Qualifire API keys.\n",
        "\n",
        "1. Sign up at [https://app.qualifire.ai](https://app.qualifire.ai?utm=agents-towards-production)\n",
        "2. Complete the onboarding and create your Qualifire API key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./assets/api-key-form.png\" alt=\"Freddie Observer\" >\n",
        "\n",
        "<img src=\"./assets/new-api-key.png\" alt=\"Freddie Observer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Once you see the \"waiting for your events...\" screen you can proceed with this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./assets/wait-for-logs.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3. Initialize Qualifire\n",
        "\n",
        "Add both your Qualifire and OpenAI API keys below to initialize the Qualifire SDK. This step is crucial as it sets up the automatic OpenTelemetry instrumentation.\n",
        "The `qualifire.init()` call is sufficient to automatically instrument and configure OpenTelemetry for tracing the LangGraph agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global QUALIFIRE_API_KEY\n",
        "QUALIFIRE_API_KEY = \"YOUR QUALIFIRE API KEY\" #@param {type:\"string\"}\n",
        "\n",
        "global OPENAI_API_KEY\n",
        "OPENAI_API_KEY = \"YOUR OPENAI API KEY\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check that the Qualifire API key is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import qualifire\n",
        "import os\n",
        "\n",
        "if QUALIFIRE_API_KEY == \"YOUR QUALIFIRE API KEY\":\n",
        "    print(\"Please replace 'YOUR QUALIFIRE API KEY' with your actual key.\")\n",
        "else:\n",
        "    qualifire.init(\n",
        "        api_key=QUALIFIRE_API_KEY,\n",
        "    )\n",
        "    print(\"Qualifire SDK Initialized Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check that the OpenAI API key is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if OPENAI_API_KEY == \"YOUR OPENAI API KEY\":\n",
        "    print(\"Please replace 'YOUR OPENAI API KEY' with your actual key for the agent to run.\")\n",
        "else:\n",
        "    print(\"OpenAI API Key set.\")\n",
        "# Note: The agent code itself will pass this to the init_chat_model function.\n",
        "# Setting it as an environment variable here is good practice if other parts of LangGraph expect it.\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define and run the LangGraph agent\n",
        "\n",
        "The following code defines a LangGraph agent that interacts with a SQL database. We will run this agent to generate some activity, which Qualifire will then trace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Agent Code\n",
        "This is an example agent but feel free to replace it with your own agent.\n",
        "\n",
        "\n",
        "This example agent is a simple chatbot that can answer questions about a given database. in our example we will use the Chinook database. \n",
        "The Chinook data model represents a digital media store, including tables for artists, albums, media tracks, invoices and customers.\n",
        "\n",
        "We are able to ask all sorts of questions about the database, in our example we will ask about the sales agent who made the most sales in 2009.\n",
        "\n",
        "The AI will then research the database, read schemas and tables and then answer the question.\n",
        "\n",
        "‚ÑπÔ∏è Note: You don't need to read the example agent code, it is just here to show you an example of how to build an agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "from LangGraph.chat_models import init_chat_model\n",
        "from LangGraph_community.utilities import SQLDatabase\n",
        "from LangGraph_community.agent_toolkits import SQLDatabaseToolkit\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "print(\"Imported necessary libraries for the agent.\")\n",
        "\n",
        "# Check if API keys are set before proceeding\n",
        "if QUALIFIRE_API_KEY == \"YOUR QUALIFIRE API KEY\" or OPENAI_API_KEY == \"YOUR OPENAI API KEY\":\n",
        "    print(\"\\nERROR: API keys are not set. Please set QUALIFIRE_API_KEY and OPENAI_API_KEY in the cells above.\\n\")\n",
        "else:\n",
        "    print(\"\\nAPI keys seem to be set. Proceeding with agent initialization.\\n\")\n",
        " \n",
        "    # Initialize the LLM\n",
        "    llm = init_chat_model(\n",
        "        \"openai:gpt-4.1\", # This can be ANY model supported by your init_chat_model\n",
        "        api_key=OPENAI_API_KEY,\n",
        "        base_url=\"https://proxy.qualifire.ai/api/providers/openai/\", # Needed for moderation we'll discuss that in the next tutorial\n",
        "        default_headers={\n",
        "            \"X-Qualifire-API-Key\": QUALIFIRE_API_KEY\n",
        "        },\n",
        "    )\n",
        "    print(\"LLM Initialized.\")\n",
        "\n",
        "    # Download the Chinook database\n",
        "    db_file_path = \"./assets/Chinook.db\"\n",
        "\n",
        "    # Setup SQL Database\n",
        "    db = SQLDatabase.from_uri(f\"sqlite:///{db_file_path}\")\n",
        "\n",
        "    # Setup SQL Database Toolkit\n",
        "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "    tools = toolkit.get_tools()\n",
        "    print(\"\\nAvailable Tools:\")\n",
        "    for tool in tools:\n",
        "        print(f\"- {tool.name}: {tool.description}\")\n",
        "\n",
        "    # Define the system prompt for the agent\n",
        "    system_prompt_string = \"\"\"\n",
        "You are an agent designed to interact with a SQL database.\n",
        "Given an input question, create a syntactically correct {dialect} query to run,\n",
        "then look at the results of the query and return the answer. Unless the user\n",
        "specifies a specific number of examples they wish to obtain, always limit your\n",
        "query to at most {top_k} results.\n",
        "\n",
        "You can order the results by a relevant column to return the most interesting\n",
        "examples in the database. Never query for all the columns from a specific table,\n",
        "only ask for the relevant columns given the question.\n",
        "\n",
        "You MUST double check your query before executing it. If you get an error while\n",
        "executing a query, rewrite the query and try again.\n",
        "\n",
        "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
        "database.\n",
        "\n",
        "To start you should ALWAYS look at the tables in the database to see what you\n",
        "can query. Do NOT skip this step.\n",
        "\n",
        "Then you should query the schema of the most relevant tables.\n",
        "\"\"\".format(\n",
        "        dialect=db.dialect,\n",
        "        top_k=5,\n",
        "    )\n",
        "\n",
        "    # Create the ReAct Agent\n",
        "    agent_executor = create_react_agent(\n",
        "        llm,\n",
        "        tools,\n",
        "        prompt=system_prompt_string,\n",
        "    )\n",
        "\n",
        "    print(\"\\nAgent executor created.\")\n",
        "\n",
        "    # Define a question and stream the agent's response\n",
        "    question = \"Which sales agent made the most in sales in 2009?\"\n",
        "    print(f\"\\nQuestion: {question}\\n\")\n",
        "    print(\"Streaming agent response:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    try:\n",
        "        for step in agent_executor.stream(\n",
        "            {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "            stream_mode=\"values\", # \"values\" provides the full state at each step\n",
        "        ):\n",
        "            # The 'messages' key contains a list of AIMessage, HumanMessage, etc.\n",
        "            # We're interested in the last message, which is usually the agent's thought or response.\n",
        "            if \"messages\" in step and step[\"messages\"]:\n",
        "                step[\"messages\"][-1].pretty_print()\n",
        "                print(\"-\" * 30)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during agent execution: {e}\")\n",
        "        print(\"This might be due to API key issues, network problems, or unexpected agent behavior.\")\n",
        "        print(\"Please check your API keys and network connection.\")\n",
        "        print(\"If the agent itself has an issue, the Qualifire traces (if captured) might provide insights.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. View Traces in Qualifire\n",
        "\n",
        "After running the agent, Qualifire (if initialized correctly) will have captured the traces of its execution.\n",
        "\n",
        "1.  Go to the Qualifire platform: [https://app.qualifire.ai/traces](https://app.qualifire.ai/traces?utm=agents-towards-production)\n",
        "2.  You should see the trace from your agent run. It might take a few moments for traces to appear.\n",
        "3.  Click on \"results\" to explore the trace and see the detailed logs, execution flow, and any insights Qualifire provides.\n",
        "\n",
        "\n",
        "### What to look for:\n",
        "*   **Our new trace:** The trace you just created should appear in the list of traces.\n",
        "*   **Spans:** Each significant operation (LLM call, tool execution, database query) should appear as a span.\n",
        "*   **LLM Interaction Details:** For spans representing LLM calls, look for attributes containing the prompt, response, token counts, and model used.\n",
        "*   **Tool Calls:** Observe how tools are called, their inputs, and outputs.\n",
        "*   **Errors:** If any errors occurred, they should be visible within the relevant spans.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The traces table\n",
        "\n",
        "<img src=\"./assets/traces-table.png\">\n",
        "\n",
        "### The trace overview\n",
        "\n",
        "<img src=\"./assets/full-trace.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Understanding the Observability Data\n",
        "\n",
        "Qualifire leverages OpenTelemetry to capture a rich set of observability data. Here's what you can typically analyze:\n",
        "\n",
        "*   **End-to-End Trace:** Visualize the entire lifecycle of a request to your agent. This includes the initial input, calls to the LLM, any tools used by the agent (like the SQLDatabaseToolkit), and the final response.\n",
        "\n",
        "*   **LLM Interactions:**\n",
        "    *   **Prompts & Completions:** See the exact prompts sent to the LLM and the completions received.\n",
        "    *   **Model & Parameters:** Confirm which model was used (e.g., `gpt-4.1`) and other parameters like temperature or max tokens if they are captured.\n",
        "    *   **Token Usage:** Monitor token consumption for cost management and to ensure you're within context limits.\n",
        "*   **Tool Usage:**\n",
        "    *   **Tool Input/Output:** See what data was passed to each tool and what the tool returned. This helps verify if tools are behaving as expected.\n",
        "*   **Performance Metrics:**\n",
        "    *   **Latency Analysis:** Pinpoint which parts of your agent's workflow are taking the most time (e.g., LLM response time, database query time, tool execution time).\n",
        "*   **Error Analysis:**\n",
        "    *   **Error Messages:** When errors occur, Qualifire can capture detailed error messages, associating them with the specific operation that failed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "In this tutorial, you've learned how to:\n",
        "1.  Initialize the Qualifire SDK in your Python application with a single line of code.\n",
        "2.  Run a LangGraph agent, with Qualifire automatically capturing observability data via OpenTelemetry in the background.\n",
        "3.  Navigate to the Qualifire platform to view and analyze the traces, logs, and insights generated by your agent.\n",
        "\n",
        "Using Qualifire provides deep visibility into your agent's operations, making it easier to debug issues, optimize performance, understand LLM interactions, and ensure your agent is behaving as expected. This is a crucial step towards building robust, production-ready AI agents.\n",
        "\n",
        "We encourage you to explore further:\n",
        "*   Test with different types of agents and LLMs.\n",
        "*   Examine the various details Qualifire provides for different operations.\n",
        "*   Consider how these observability features can fit into your MLOps lifecycle for agents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Thank you for completing the tutorial! üôè\n",
        "we'd like to offer you 1 free month of the Pro plan to help you get started with Qualifire. use code `NIR1MONTH` at checkout\n",
        "\n",
        "For more details visit [https://qualifire.ai](https://qualifire.ai?utm=agents-towards-production)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "build-influence",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
